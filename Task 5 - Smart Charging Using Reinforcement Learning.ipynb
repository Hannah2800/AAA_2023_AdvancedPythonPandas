{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45eabde9",
   "metadata": {},
   "source": [
    "# Smart Charging Using Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b05d39",
   "metadata": {},
   "source": [
    "Simple simpy example from workshop (ChargingEV.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab911568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car 0 arriving at 0\n",
      "Car 0 starting to charge at 0\n",
      "Car 1 arriving at 2\n",
      "Car 1 starting to charge at 2\n",
      "Car 2 arriving at 4\n",
      "Car 0 leaving the bcs at 5\n",
      "Car 2 starting to charge at 5\n",
      "Car 3 arriving at 6\n",
      "Car 1 leaving the bcs at 7\n",
      "Car 3 starting to charge at 7\n",
      "Car 4 arriving at 8\n",
      "Car 5 arriving at 10\n",
      "Car 2 leaving the bcs at 10\n",
      "Car 4 starting to charge at 10\n",
      "Car 6 arriving at 12\n",
      "Car 3 leaving the bcs at 12\n",
      "Car 5 starting to charge at 12\n",
      "Car 7 arriving at 14\n",
      "Car 4 leaving the bcs at 15\n",
      "Car 6 starting to charge at 15\n",
      "Car 8 arriving at 16\n",
      "Car 5 leaving the bcs at 17\n",
      "Car 7 starting to charge at 17\n",
      "Car 9 arriving at 18\n",
      "Car 10 arriving at 20\n",
      "Car 6 leaving the bcs at 20\n",
      "Car 8 starting to charge at 20\n",
      "Car 11 arriving at 22\n",
      "Car 7 leaving the bcs at 22\n",
      "Car 9 starting to charge at 22\n",
      "Car 12 arriving at 24\n",
      "Car 8 leaving the bcs at 25\n",
      "Car 10 starting to charge at 25\n",
      "Car 13 arriving at 26\n",
      "Car 9 leaving the bcs at 27\n",
      "Car 11 starting to charge at 27\n",
      "Car 14 arriving at 28\n",
      "Car 15 arriving at 30\n",
      "Car 10 leaving the bcs at 30\n",
      "Car 12 starting to charge at 30\n",
      "Car 16 arriving at 32\n",
      "Car 11 leaving the bcs at 32\n",
      "Car 13 starting to charge at 32\n",
      "Car 17 arriving at 34\n",
      "Car 12 leaving the bcs at 35\n",
      "Car 14 starting to charge at 35\n",
      "Car 18 arriving at 36\n",
      "Car 13 leaving the bcs at 37\n",
      "Car 15 starting to charge at 37\n",
      "Car 19 arriving at 38\n",
      "Car 14 leaving the bcs at 40\n",
      "Car 16 starting to charge at 40\n",
      "Car 15 leaving the bcs at 42\n",
      "Car 17 starting to charge at 42\n",
      "Car 16 leaving the bcs at 45\n",
      "Car 18 starting to charge at 45\n",
      "Car 17 leaving the bcs at 47\n",
      "Car 19 starting to charge at 47\n",
      "Car 18 leaving the bcs at 50\n",
      "Car 19 leaving the bcs at 52\n"
     ]
    }
   ],
   "source": [
    "import simpy\n",
    "\n",
    "env = simpy.Environment()\n",
    "bcs = simpy.Resource(env, capacity=2)\n",
    "\n",
    "\n",
    "def car(env, name, bcs, driving_time, charge_duration):\n",
    "    # Simulate driving to the BCS\n",
    "    yield env.timeout(driving_time)\n",
    "\n",
    "    # Request one of its charging spots\n",
    "    print('%s arriving at %d' % (name, env.now))\n",
    "    with bcs.request() as req:\n",
    "        yield req\n",
    "\n",
    "        # Charge the battery\n",
    "        print('%s starting to charge at %s' % (name, env.now))\n",
    "        yield env.timeout(charge_duration)\n",
    "        print('%s leaving the bcs at %s' % (name, env.now))\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    env.process(car(env, 'Car %d' % i, bcs, i * 2, 5))\n",
    "\n",
    "\n",
    "env.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c2506",
   "metadata": {},
   "source": [
    "## Learning Resources and environments we can use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efe2e1",
   "metadata": {},
   "source": [
    "- (Alternative: Simpy)\n",
    "\n",
    "- OpenAI gym\n",
    "    - [Official Gymnasium GitHub](https://github.com/Farama-Foundation/Gymnasium)\n",
    "    - [Gymnasium Docu](https://gymnasium.farama.org/)\n",
    "        - [Creating a Gymnasium Environment](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/)\n",
    "        - [Lunar Lander example](https://gymnasium.farama.org/environments/box2d/lunar_lander/)\n",
    "    - [OpenAI Learning platform for Gymnasium](https://spinningup.openai.com/en/latest/index.html)\n",
    "        - [OpenAI Algorithms](https://spinningup.openai.com/en/latest/algorithms/ddpg.html#background)\n",
    "\n",
    "- [Here is a good resource for all deep-RL algorithms](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch/blob/master/README.md) (look into the results folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9405416",
   "metadata": {},
   "source": [
    "## Finite Markov Decision Process (MDP) (M+B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a71314",
   "metadata": {},
   "source": [
    "- getState() and maxAction() and plotRunningAverage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb3b71",
   "metadata": {},
   "source": [
    "A **Markov Process** (or Markov Chain) is a tuple ‚ü®S, A, P, R‚ü©\n",
    "- S is a set of **states**\n",
    "    - States: time, battery_level, (charging_rate), (atHome)\n",
    "        - time: Discrete 15-minute intervals from 2 p.m. to 4 p.m. (count down?)\n",
    "        - battery_level: The current battery level (from 0 kW to battery capacity kW)\n",
    "        - charging_rate: The current charging rate (between 0 kW and the highest rate (e.g., 22 kW (We need to choose)))\n",
    "        - atHome: Indicator if the agent is at home or departured\n",
    "- A is a set of **actions**\n",
    "    - Actions: {zero: 0 kW, low: 7 kW, medium: 14 kW, high: 21 kW}\n",
    "        - The actions are the discrete charging rates that the agent can choose at each discrete timestep.\n",
    "- P is a state **transition probability** function, (P<sup>a</sup><sub>SS'</sub> = P[S<sub>t</sub> = s'| S<sub>t-1</sub> = s, A<sub>t-1</sub> = a])\n",
    "    - Transition Probability:\n",
    "- R is a **reward** function of states and actions\n",
    "    - Reward:\n",
    "        - Running out of energy: eg. -1000\n",
    "        - Charging costs: i.e.,  charging cost (t,p) = ‚àë<sub>ùë°‚ààùëá</sub> ùõº<sub>ùë°</sub> ùëí<sup>ùëù</sup>), where ùõº<sub>ùë°</sub> is the time coefficient and p is the charging rate.\n",
    "    - Reward function:\n",
    "    \n",
    "**Goal:** Finding the optimal policies (which action to take in different states)  \n",
    "**Trade-off:** The agent‚Äôs goal is to avoid running out of energy (you should consider a very high penalty for running out of energy) and to minimize the recharging cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827af11",
   "metadata": {},
   "source": [
    "**Further Assumptions:**\n",
    "- Battery capacity: \n",
    "- Energy demand function: stochastic value following a normal distribution\n",
    "    - Parameters: ùúá= 30 kWh, ùúé = 5 kWh (Note: must be generated exactly when the driver wants to leave.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d1730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "293dec5c",
   "metadata": {},
   "source": [
    "## First RL-model: SARSA (TD control problem, On-Policy) (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ee3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7765762",
   "metadata": {},
   "source": [
    "## Second RL-model: Q-learning (TD control problem, Off-Policy) (M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e2934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b40c5f40",
   "metadata": {},
   "source": [
    "## (Second RL-model advanced: Double Q-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc885dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b966d54d",
   "metadata": {},
   "source": [
    "## Third RL-model: Deep Q-learning\n",
    "Build this in Google Colab with GPU environment selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bee72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
